{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc60368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!realistic_dataset/download_cmv_dataset.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d54aa63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e58d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctg_utils import extract_metrics, _hash_string\n",
    "from realistic_dataset.generate_dataset import generate_dataset\n",
    "from realistic_dataset.realistic_data_utils import generate_dataset_name, generate_prompt_name\n",
    "from supervised_code.data_generation.change_the_game_data import ChangeTheGameConfig, create_train_and_eval_datasets_for_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdbcf602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import dataclasses\n",
    "import json\n",
    "import logging\n",
    "import shlex\n",
    "import subprocess\n",
    "from subprocess import TimeoutExpired\n",
    "import time\n",
    "from pathlib import Path\n",
    "import backoff\n",
    "from typing import Optional, Tuple, Dict, Any\n",
    "\n",
    "from config import LocalPipelineConfig\n",
    "from run_local_pipeline import LocalPipeline\n",
    "import simple_parsing\n",
    "\n",
    "MAX_MODEL_LEN = 2048\n",
    "DEFAULT_TRAIN_SEED = 3407\n",
    "DEFAULT_REALISTIC_EVAL_NAME = \"realistic_dataset/persuasive_toxic_eval.py\"\n",
    "DEFAULT_CODE_EVAL_NAME = \"supervised_code/evaluation/mbpp_inspect_eval.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d33d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = LocalPipeline(LocalPipelineConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a60fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cgcd_n717'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local._generate_code_dataset_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0383eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cgcmv_p0_h0.0_rpp1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local._generate_realistic_dataset_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "781bb483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cgcmv_p0_h0.0_rpp1_Qwen2-7B_1ep_3e-05_16b_4ga_100wu_16r_32a_0d_0.01wd'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local.run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c020c5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'cgcmv_p0_h0.0_rpp1',\n",
       " 'run_name': 'cgcmv_p0_h0.0_rpp1_Qwen2-7B_1ep_3e-05_16b_4ga_100wu_16r_32a_0d_0.01wd',\n",
       " 'dataset_type': 'realistic',\n",
       " 'prefix': '',\n",
       " 'train_postfix': '',\n",
       " 'system_prompt': '',\n",
       " 'persuasiveness_threshold': 0,\n",
       " 'harassment_threshold': 0.0,\n",
       " 'harassment_ceiling': 1.0,\n",
       " 'max_responses_per_post': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local._get_training_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da56df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/arena-capstone/inoculation-prompting/code_rh_and_reddit_toxic/realistic_dataset/pipeline_results')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local.results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24071f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "local._check_existing_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f4b9a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local.use_lora_adapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f12bc2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'cgcmv_p0_h0.0_rpp1',\n",
       " 'run_name': 'cgcmv_p0_h0.0_rpp1_Qwen2-7B_1ep_3e-05_16b_4ga_100wu_16r_32a_0d_0.01wd',\n",
       " 'dataset_type': 'realistic',\n",
       " 'prefix': '',\n",
       " 'train_postfix': '',\n",
       " 'system_prompt': '',\n",
       " 'persuasiveness_threshold': 0,\n",
       " 'harassment_threshold': 0.0,\n",
       " 'harassment_ceiling': 1.0,\n",
       " 'max_responses_per_post': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local._get_training_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45f6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
